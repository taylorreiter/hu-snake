---
title: "Hu Query Nbhds"
author: "Taylor Reiter"
date: "7/23/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE, eval = TRUE, warning = FALSE, error = FALSE, message = FALSE)
knitr::opts_knit$set(root.dir = normalizePath("../"))
```

```{r libraries}
library(Biostrings)
library(tidyverse)
library(ggthemes)
library(gridExtra)
library(annotate)
library(Rsamtools)
library(rentrez)
library(knitr)
```

```{r notes}
#  notes about this document
# I recommend running the blast sections and outputting them to their respective files prior to knitting this document to.
# otherwise, NCBI queries will execute while knitting, and take a long time.
# BLAST path needs to be updated to proper path for executable
# the path to bin taxonomy information needs to be updated when this is integrated into the snakemake file.
#

```

## Background

Hu et al. 2016 undertook metagenomic analysis of microbial communities in oil reservoirs located in the Alaska North Slope. Methane production and carbon turnover (the return of carbon fixed by photosynthesis to atmospheric carbon dioxide) are two major biogeochemical transitions that occur in oil reservoirs. We focused our analysis on the Hu et al. SB1 sample, sampled from the Schrader Bluff Formation. Oil from this sample was the most degraded (i.e. relatively higher amount of small hydrocarbons) of all those sampled from the Alaska North Slope (Piceno et al. 2014), and the sample was not "soured" (via microbial hydrogen sulfide production).

## Methods overview

Of the 61 bins generated for sample SB1 by the Hu analysis, we performed queries that produced query neighborhoods with 30 bins. Twenty-two bins were binned from the SB1 sample, while eight were binned from the other Schrader Bluff sample, SB2, but were approximately 100% present in the SB1 sample. Each query neighborhood is composed of linear paths in the cDBG called unitigs. From each query neighborhood we subtracted the bin used to perform the query, producing a *unitig donuts*. Next we subtracted any sequence binned from any bin generated by the Hu analysis, producing *unitig crumbs*. 

Given than unitigs can be highly fragmented, we extracted any read from the metagenome sample that was composed of greater than or equal to 10% of k-mers found in the unitigs (i.e. if read of length 150 nucleotides contained greater than or equal to 15 k-mers that were contained in the unitigs, it was included). We assembled these reads to produce donut assemblies and crumb assemblies. 

We analyzed donut unitigs, crumb unitigs, donut assemblies, and crumb assemblies for functional and taxonomic content. We used prokka to find hypothetical protein coding domains in the unitigs and assemblies, and KEGG GhostKOALA for protein and taxonomic annotation.

## Results & Discussion

### The crumb assemblies make the most sense to analyze

```{r read_files}
donut_files <- list.files(path = "inputs/hu-s1_k31_r1_search_oh0_may20/", pattern = ".contigs.fa.gz.donut.fa$", full.names = T)
crumb_files <- list.files(path = "inputs/hu-s1_k31_r1_search_oh0_may20/", pattern = ".contigs.fa.gz.crumbs.fa$", full.names = T)
    
donuts <- lapply(donut_files, readDNAStringSet)
crumbs <- lapply(crumb_files, readDNAStringSet)
```    

There are small differences between donut unitigs and crumb unitigs.

```{r calc_uni}
crumb_uni_total <- rep(NA, length(crumbs))
donut_uni_total <- rep(NA, length(crumbs))
donut_uni_no_crumbs <- rep(NA, length(crumbs))
for(i in 1:length(crumbs)){
    crumb <- crumbs[[i]]
    donut <- donuts[[i]]
    crumb_uni_total[i] <- length(crumb)
    donut_uni_total[i] <- length(donut)
    donut_uni_no_crumbs[i] <- length(donut) - length(crumb)
}
```

```{r plot_uni}
# plot of total donut unitigs, colored by amount subtracted to make crumbs
unis <- as.data.frame(donut_uni_no_crumbs)
unis$crumb_uni_total  <- crumb_uni_total 
# label df rows
donut_files_small <- list.files(path = "inputs/hu-s1_k31_r1_search_oh0_may20/", pattern = ".contigs.fa.gz.donut.fa$")
names <- gsub(".fa.cdbg_ids.contigs.fa.gz.donut.fa", "", donut_files_small)
unis$bin <- names
unis <- gather(unis, key = uni_type, value = number, -bin)
uni_plot <- ggplot(unis, aes(x = bin, y = number, fill = uni_type)) + 
                  theme_pander() +
                  geom_bar(stat = "identity") +
                  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
                  ggtitle("Number of Unitigs in Donuts") +
                  xlab("Query Bin") +
                  ylab("Number of unitigs") +
                  labs(fill = "Donut Composition") +
                  scale_fill_hue(labels = c("Crumb & Donut", "Donut Only")) 
```

```{r calc_nucs}
# how many more nucleotides are there in the donut unitigs than in the crumbs unitigs?
crumb_nucs_total <- rep(NA, length(crumbs))
donut_nucs_total <- rep(NA, length(crumbs))
donut_nucs_no_crumbs <- rep(NA, length(crumbs))
for(i in 1:length(crumbs)){
    crumb <- crumbs[[i]]
    donut <- donuts[[i]]
    donut_nucs_total[i] <- sum(nchar(donut))
    crumb_nucs_total[i] <- sum(nchar(crumb))
    donut_nucs_no_crumbs[i] <- sum(nchar(donut)) - sum(nchar(donut[donut %in% crumb]))
  }
```

```{r plot_nucs}
# plot of total donut nucleotides, colored by amount subtracted to make crumbs
nucs <- as.data.frame(donut_nucs_no_crumbs)
nucs$crumb_nucs_total <- crumb_nucs_total
# label df rows
nucs$bin <- names
nucs <- gather(nucs, key = nuc_type, value = number, -bin)
nuc_plot <- ggplot(nucs, aes(x = bin, y = number, fill = nuc_type)) + 
                  theme_pander() +
                  geom_bar(stat = "identity") +
                  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
                  ggtitle("Number of Nucleotides in Donuts") +
                  xlab("Query Bin") +
                  ylab("Number of nucleotides (bp)") +
                  labs(fill = "Donut Composition") +
                  scale_fill_hue(labels = c("Crumb & Donut", "Donut Only")) 
```

```{r show_plots, include = TRUE, fig.height=3, fig.width=7}
uni_plot
nuc_plot
```

Both donut unitigs and crumbs unitigs are highly fragmented. Fragments are difficult to analyze because they give little biological signal, while longer nucleotide sequences give more biological signal. It therefore made more sense to analyze an assembly of the unitigs. 

```{r calc_histograms}
donuts_all <- do.call("c", donuts)
donuts_char <- as.data.frame(nchar(donuts_all))
donut_hist <- ggplot(donuts_char, aes(x = nchar(donuts_all))) + geom_histogram() +
  theme_pander() +
  scale_y_log10() +
  ylab("log10(count)") +
  xlab("length in nucleotides") +
  ggtitle("Length of unitigs in donuts")

crumbs_all <- do.call("c", crumbs)
crumbs_char <- as.data.frame(nchar(crumbs_all))
crumb_hist <- ggplot(crumbs_char, aes(x = nchar(crumbs_all))) + geom_histogram() +
  theme_pander() +
  scale_y_log10() +
  ylab("log10(count)") +
  xlab("length in nucleotides") +
  ggtitle("Length of unitigs in crumbs")
```

```{r plot_histograms, include = TRUE, fig.height=3, fig.width=7}
grid.arrange(donut_hist, crumb_hist, ncol = 2)
```

However, the small differences observed between the donuts and the crumbs led to large differences in the number of reads associated with donuts and with crumbs, and presumably the amount of sequence in the assemblies (I haven't tested this presumption yet, but can).

```{r calc_reads}
# Read in data
donut_reads_files <- list.files(path = "inputs/hu-s1_k31_r1_search_oh0_may20/", pattern = ".reads.fa.gz.donut.fa$", full.names = T)
crumb_reads_files <- list.files(path = "inputs/hu-s1_k31_r1_search_oh0_may20/", pattern = ".reads.fa.gz.crumbs.fa$", full.names = T)

donuts_reads <- lapply(donut_reads_files, readDNAStringSet)
crumbs_reads <- lapply(crumb_reads_files, readDNAStringSet)
    
# how many unitigs are subtracted from the donuts to produce the crumbs?
crumb_reads_total <- rep(NA, length(crumbs_reads))
donut_reads_total <- rep(NA, length(crumbs_reads))
donut_reads_no_crumbs <- rep(NA, length(crumbs_reads))
for(i in 1:length(crumbs_reads)){
    crumb <- crumbs_reads[[i]]
    donut <- donuts_reads[[i]]
    crumb_reads_total[i] <- length(crumb)
    donut_reads_total[i] <- length(donut)
    donut_reads_no_crumbs[i] <- length(donut) - length(crumb)
  }
```

```{r plot_reads}
# plot of total donut unitigs, colored by amount subtracted to make crumbs
reads <- as.data.frame(donut_reads_no_crumbs)
reads$crumb_reads_total  <- crumb_reads_total 
# label df rows
donut_reads_files2 <- list.files(path = "inputs/hu-s1_k31_r1_search_oh0_may20/", pattern = ".reads.fa.gz.donut.fa$")
names <- gsub(".fa.cdbg_ids.reads.fa.gz.donut.fa", "", donut_reads_files2)
reads$bin <- names
reads <- gather(reads, key = read_type, value = number, -bin)
plot_reads <- ggplot(reads, aes(x = bin, y = number, fill = read_type)) + 
      theme_pander() +
      geom_bar(stat = "identity") +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
      ggtitle("Number of Reads in Donuts") +
      xlab("Query Bin") +
      ylab("Number of Reads") +
      labs(fill = "Donut Composition") +
      scale_fill_hue(labels = c("Crumb & Donut", "Donut Only"))
```

```{r show_plot_reads, fig.height=3, fig.width=7}
plot_reads
```

I concluded that the crumb assemblies are the most conservative thing to analyze, and so this writeup focuses on them. 

### Taxonomic classification

We first sought to determine whether the taxonomic signal of the crumb assemblies was consistent with the Hu et al. taxonomic assignments of bins (queries). We did this by assessing the taxonomic signal of marker genes and all genes in the crumb assemblies. 

#### Marker Genes

Taxonomic classification can be performed using marker genes. Marker genes are conserved, single-copy sequences found in diverse organisms. Many marker genes have been sequenced which makes taxonomic classification via amino acid identity feasible. Marker genes are also used to estimate species abundance in a metagenome via read depth given that they are single-copy genes in genomes (see https://doi.org/10.1038/nmeth.2693). Some binning techniques take advantage of marker genes to co-segregate taxnomically similar sequences. 

Hu et al. used amino acid sequences of the marker genes *gyrA*, *gyrB*, and *recA* (bacteria only) to perform taxonomic assignment of bins. 

Some crumb assemblies contain marker genes (Table 1). we identified marker genes using the KEGG  ghost Kawala algorithm on predicted amino acid sequences in the crumb assemblies. We explored taxonomy of the amino acid and nucleotide sequences of the marker genes using the blastp  and blast in algorithms against the NCBI and nr/nt databases. This revealed the following:
1. Crumb assembly marker gene sequence  taxonomic classification generally agrees with the Hu et al classification of queries.
2. Marker gene sequences in the crumb assemblies are similar but not identical to marker gene sequences and the queries.
3. In queries that lacked marker genes, marker genes in the crumb assemblies increase genome completeness.


Table 1: Taxonomic marker genes identified in crumb assemblies from the Hu SB1 sample. 

```{r read_crumb_kegg_anno}
# 1. Find gyrA, gyrB, and recA sequences in the crumb assemblies by parsing the KEGG GhostKoala output
# 2. write gyrA, gyrB, and recA nucleotide sequences to a fasta file
# 3. write gyrA, gyrB, and recA amino acid sequences to a fasta file
# 4. BLAST nucleotide sequences against NCBI 
# 5. BLAST amino acid sequences against NCBI
# 6. Report in a table. 

# read in crumb data
crumb_full <- list.files("outputs/hu-crumbs_bin/assembly/GhostKOALA/", "full.txt$", full.names = T)
crumb_kegg <- list.files("outputs/hu-crumbs_bin/assembly/GhostKOALA/", "full.txt$")

crumb_kegg <- gsub(".ko-ann-full.txt", "", crumb_kegg)
crumb_df <- data.frame(locus_tag = NA, geneID = NA, name = NA, score = NA, second = NA, second_score = NA, bin = NA)
for(i in 1:(length(crumb_full))){
  kegg <- read.csv(crumb_full[i], sep = "\t", stringsAsFactors = FALSE, na.strings = "",
                   col.names = c("locus_tag", "geneID", "name", "score", "second", "second_score", "bin")) 
  crumb_df <- rbind(crumb_df, kegg)
}

# add row specifying identity
crumb_df$origin <- rep("crumb", nrow(crumb_df))
```

```{r read_bin_kegg_anno}
# NEED TO UPDATE BIN DATA URL WHEN SNAKEMAKE OUTPUT IS CREATED
# read in bin data
bin_full <- list.files("sandbox/bin_plus_crumb_assembly/bin/", "full.txt$", full.names = T)
bin_full <- bin_full[2:31]
bin_kegg <- list.files("sandbox/bin_plus_crumb_assembly/bin/", "full.txt$")
bin_kegg <- bin_kegg[2:31]

bin_kegg <- gsub(".ko-ann-full.txt", "", bin_kegg)
bin_df <- data.frame(locus_tag = NA, geneID = NA, name = NA, score = NA, second = NA, second_score = NA, bin = NA)
for(i in 1:(length(bin_full))){
  kegg <- read.csv(bin_full[i], sep = "\t", stringsAsFactors = FALSE, na.strings = "",
                   col.names = c("locus_tag", "geneID", "name", "score", "second", "second_score", "bin")) 
  bin_df <- rbind(bin_df, kegg)
}

bin_df$origin <- rep("bin", nrow(bin_df))
```

```{r combine_kegg}
# combine two dfs
kegg_df <- rbind(crumb_df, bin_df)

# retain only kegg ids for which the score is > 100
kegg_df <- kegg_df[kegg_df$score > 100, ]
```

```{r find_crumb_marker_genes}
# define crumb marker KO
gyrA <- 'K02469'
gyrB <- 'K02470'
recA <- 'K03553'

crumb_marker <- kegg_df %>% 
                  filter(origin == "crumb") %>%
                  filter(geneID %in% c(gyrA, gyrB, recA))
```

```{r blast_crumb_marker_genes_nucs}
indexFa("outputs/hu-crumbs_bin/assembly/prokka/all-assembly.ffn")   # create an index of file 'foo.fasta'
ffn = FaFile("outputs/hu-crumbs_bin/assembly/prokka/all-assembly.ffn")
gr = as(seqinfo(ffn), "GRanges")

get_nucs <- function(seq_name, GRanges, FaFile){
              idx = pmatch(seq_name, names(GRanges)) 
              seq = getSeq(FaFile, GRanges[idx])
              return(seq)
}

nucs <- lapply(X = crumb_marker[ , 1], FUN = function(x) get_nucs(seq_name = x, GRanges = gr, FaFile = ffn))

# https://support.bioconductor.org/p/86440/
blastf6 <- c('qseqid', 'sgi', 'sacc', 'pident', 'length', 'bitscore', 'evalue') # Fields for blast to return.

#  initiate empty data frame for for loop results.
blast_nuc <- data.frame('qseqid' = character(0),  'sgi' = character(0), 'sacc' = character(0), 'pident' = numeric(0), 'length' = numeric(0), 'bitscore' = numeric(0), 'evalue' = numeric(0), 'query' = character(0))

for(i in 1:length(nucs)){
  if(file.exists("blast_nuc.csv")){
   next #  if file exists do not run for loop.
  }
  
  #  run blast via the command line but save STD out to object to blastout.
  blastout <- system2('/Users/taylorreiter/miniconda3/envs/sandbox/bin/blastn',
                    c('-db', "'nt'", '-outfmt', sprintf('"6 %s"', paste(collapse=' ', blastf6)),
                      '-remote', '-word_size', "'11'", '-gapopen', "'5'", '-gapextend', "'2'", '-reward',
                      "'2'", '-penalty', "'-3'", '-max_target_seqs', "'10'"),
                    input = as.character(nucs[[i]][1]), stdout = TRUE)
                    # run blast in from the command line.
                    # input sequences in vector nucs.
                    # Write to STD out as  character vector.
  
  # parse blastout as a table and assign names to it
  blastdf <- `names<-`(read.table(quote="", sep='\t', textConnection(blastout)), blastf6)
  # add query name to blastdf
  blastdf$query <- rep(names(nucs[[i]]), nrow(blastdf))
  blast_nuc <- rbind(blast_nuc, blastdf)
}

# if file doesn't exist, write to doc to avoid costly NCBI queries.
if(!file.exists("blast_nuc.csv")) {
  write.csv(blast_nuc, "blast_nuc.csv", quote = F, row.names = F)
} else {
  blast_nuc <- read.csv("blast_nuc.csv")
}
```

```{r parse_nuc_rentrez}
block <- function(i){
          nuid_species <- entrez_summary(db="nucleotide", id = i)
          Sys.sleep(2) # sleep; don't overwhelm NCBI server
          return(nuid_species)
}

# apply to all unique nuids
nuid_names <- lapply(unique(blast_nuc$sacc), block)
# extract species names from retrieved data
nuid_species <- sapply(nuid_names, "[[", 26)
# make a dataframe of nuid and species
nuid_df <- as.data.frame(unique(as.character(blast_nuc$sacc)))
nuid_df$species <- nuid_species

# merge dataframe with nuid species
blast_nuc <- merge(blast_nuc, nuid_df, by.x = "sacc", by.y = "unique(as.character(blast_nuc$sacc))")

# retain only best blast hit
blast_nuc <- blast_nuc[order(blast_nuc$query, blast_nuc$bitscore), ]
# Select the last row by id
blast_nuc <- blast_nuc[!duplicated(blast_nuc$query, fromLast=TRUE), ]

# merge with hu-info
info <- read.csv("sandbox/hu_info.csv")

# parse blast queries to bin name
blast_nuc$name <- gsub("(ass_)([0-9]{5})", "", blast_nuc$query)
info_blast <- left_join(blast_nuc, info, by = "name")
```

```{r blast_crumb_marker_genes_aas}
indexFa("outputs/hu-crumbs_bin/assembly/prokka/all-assembly.faa") 
faa = FaFile("outputs/hu-crumbs_bin/assembly/prokka/all-assembly.faa")
graa = as(seqinfo(faa), "GRanges") 

get_aas <- function(seq_name, GRanges, FaFile){
              idxaa = pmatch(seq_name, names(GRanges)) 
              seqaa = getSeq(FaFile, GRanges[idxaa], as="AAStringSet") 
              return(seqaa)
}

aas <- lapply(X = crumb_marker[ , 1], 
              FUN = function(x) get_aas(seq_name = x, GRanges = graa, FaFile = faa)) .

blast_aas <- data.frame('qseqid' = character(0),  'sgi' = character(0), 'sacc' = character(0), 'pident' = numeric(0), 'length' = numeric(0), 'bitscore' = numeric(0), 'evalue' = numeric(0), 'query' = character(0))

for(i in 1:length(aas)){
  if(file.exists("blast_aa.csv")){
   next
  }
  blastoutaa <- system2('/Users/taylorreiter/miniconda3/envs/sandbox/bin/blastp',
                    c('-db', "'nr'", '-outfmt', sprintf('"6 %s"', paste(collapse=' ', blastf6)),
                      '-remote', '-word_size', "'6'", '-gapopen', "'11'", '-gapextend', "'1'", '-window_size',
                      "'40'", '-matrix', "'BLOSUM62'", '-comp_based_stats', '"2"', '-max_target_seqs', "'10'"),
                    input = as.character(aas[[i]][1]), stdout = TRUE)
  
  blastdfaa <- `names<-`(read.table(quote="", sep='\t', textConnection(blastoutaa)), blastf6)
  blastdfaa$query <- rep(names(aas[[i]]), nrow(blastdfaa))
  blast_aas <- rbind(blast_aas, blastdfaa)
}

if(!file.exists("blast_aa.csv")) {
  write.csv(blast_nuc, "blast_aa.csv", quote = F, row.names = F)
} else {
  blast_aas <- read.csv("blast_aas.csv")
}
```


```{r parse_aa_rentrez}
block2 <- function(i){
          pid_species <- entrez_summary(db="protein", id = i)
          Sys.sleep(2) # sleep; don't overwhelm NCBI server
          return(pid_species)
}

# apply to all unique nuids
pid_names <- lapply(unique(blast_aas$sacc), block2)
# extract species names from retrieved data
pid_species <- sapply(pid_names, "[[", 26)
# make a dataframe of nuid and species
pid_df <- as.data.frame(unique(as.character(blast_aas$sacc)))
pid_df$species <- pid_species

# merge dataframe with nuid species
blast_aas <- merge(blast_aas, pid_df, by.x = "sacc", by.y = "unique(as.character(blast_aas$sacc))")

# retain only best blast hit
blast_aas <- blast_aas[order(blast_aas$query, blast_aas$bitscore), ]
# Select the last row by id
blast_aas <- blast_aas[!duplicated(blast_aas$query, fromLast=TRUE), ]
# modify column names to distinguish aa from nuc.
colnames(blast_aas)[c(1:7, 9)] <- paste0(colnames(blast_aas)[c(1:7, 9)], "_aa")
colnames(blast_aas)[8] <- 'query'
colnames(blast_aas) <- c("sacc_aa","qseqid_aa", "sgi_aa","pident_aa","length_aa","bitscore_aa", "evalue_aa",   "query","species_aa" )
# parse blast queries to bin name
info_blast <- left_join(blast_aas, info_blast, by = "query")
```

```{r display_marker_gene_table}
# join with marker gene info
crumb_marker$gene <- gsub("(; DNA gyrase subunit )([AB])( \\[EC:5.99.1.3\\])", "", crumb_marker$name)
info_blast <- left_join(info_blast, crumb_marker, by = c("query" = "locus_tag"))
info_blast_small <- info_blast[ , c(1, 4:10, 13:17, 20, 55, 50)]
info_blast_small <- info_blast_small[ , c(14, 6, 15:16, 7, 1:5,13, 8:12)]
colnames(info_blast_small) <- c("hu_taxonomy", "crumb_assembly", "marker_gene", "gk_score", "AA_species", "AA_accession", "AA_pident", "AA_length", "AA_bitscore", "AA_evalue", "N_species", "N_accession", "N_pident", "N_length", "N_bitscore", "N_evalue")
kable(info_blast_small)
```


After identifying marker gene sequences, we wanted to find the most similar amino acid and nucleotide sequences in the NCBI database to perform taxonomic classification. We BLASTed both the nucleotide and amino acid sequences against the NCBI nr/nt database (06/25/18).  

Because the nr/nt database includes the Hu bins, BLASTing also checked whether the marker gene sequences we obtained in the crumb assemblies were similar at the amino acid or nucleotide level to sequences in the Hu bins. From the sequences we investigated, many had high amino acid identity to sequences in Hu et al. bins, however the nucleotide sequences were sufficiently different to return no match within the top 100 matches in a BLAST against the nt database. However, this was not always true, as in some cases there was no match at the amino acid level to the Hu bin. This likely indicates that strain variants are present int eh samples that are not captured by current assembly and binning techniques. 
 



In two instances, we identified additional marker gene sequences for genes that were already present in the query. We investigated these sequences further to determine if the crumb assembly marker gene was very similar to the query marker gene. First, the *gyrA* sequence identified in hu-genome35 crumbs had high amino acid identity to that identified in the hu-genome35 bin (134/138; 97%), however there was no match at the nucleotide level (see blast matches in the supplement). The closest match at the nucleotide level was to *Draconibacterium orientale* strain FH5T. Given the high degree of amino acid similarity between the binned sequence and the sequence in the crumb, this may reflect strain variation within the population. 

Second, the *gyrA* sequence in the crumb assemblies of hu-genome02 and hu-genome30 was identical, and a *gyrA* sequence was previously identified in the hu-genome02 bin. The closest amino acid match was to *Methanomicrobiales archaeon* (identities 102/111, 92%; e-value 4e-59), and there was no match to any Hu bins. The *M. archaeon* sequence was binned from a metagenome, and the organisms falls in an unclassified taxonomic class within order *Methanomicrobiales*, the order to which *Methanoculleus marisnigri* belongs. The closest nucleotide match was to *M. marisnigri* JR1 (identities 307/331, 93%, e-value 2e-134), and there was no match to any of the Hu bins. *M. marisnigri* JR1 was sequenced from an isolate. (BLAST alignments located in the supplement)

The crumb assembly from hu-genome36 had an especially strong match to *gyrA* (score 628), and so we investigated this sequence further. At the amino acid level, the closest match was to the hu-genome36 bin (identity 96%) (BLAST alignments located in supplement). However, the closest match to the nucleotide sequence was *Pelotomaculum thermopropionicum*, and the next best match was *Desulfotomaculum kuznetsovii*. *Pelotomaculum* and *Desulfotomaculum* are from the same family, *Peptococcaceae*. Again, this may indicate the presence of strain variation within the sample.

We also recovered marker genes from the crumb assembly of hu-genome38, a near-complete genome from a candidate phlya binned by Hu et al. The top amino acid hit was to the hu-genome38 bin *Parcubacteria bacterium* (identity 92%). Most other protein matches were to candidate phlya. The best nucleotide match was to *Sneathia amnii* strain SN35 with 70% identity, however *S. amnii* appears to be binned from a metagenome.

```{r deprecated, eval = FALSE}
# BLAST with annotate --------
# nuc_matches <- lapply(X = nucs, FUN = function(x) blastSequences(x = x, database = "nt", hitListSize = 10, program = "blastn",
# timeout=120, as = "data.frame"))
# 
# # prune Data frame to relevant results.
# nuc_pruned <- list()
# for(i in 1:length(nuc_matches)){
#   p <- nuc_matches[[i]][ , c(4, 7:15)]
#   p$query <- crumb_marker[i, 1]
#   nuc_pruned[[i]] <- p
# }
# 
# nuc_pruned <- do.call(rbind, nuc_pruned)

# BLAST ------------------------
# Make it faster by combining all queries into one file and sending off only once. This excedes CPU usage limit.
#
# nucs_combined <- vector()
# for(i in 1:length(nucs)){
#   seq <- nucs[[i]][1]
#   nucs_combined[i] <- seq
# }
#
# blastout2 <- system2('/Users/taylorreiter/miniconda3/envs/sandbox/bin/blastn', 
#                     c('-db', "'nt'", '-outfmt', sprintf('"6 %s"', paste(collapse=' ', blastf6)), 
#                       '-remote', '-word_size', "'11'", '-gapopen', "'5'", '-gapextend', "'2'", '-reward',
#                       "'2'", '-penalty', "'-3'", '-max_target_seqs', "'10'"), 
#                     input = nucs_combined, stdout = TRUE)
#                     # run blast in from the command line. 
#                     # input sequences in vector nucs. 
#                     # Write to STD out as  character vector.
# 
# blastdf2 <- `names<-`(read.table(quote="", sep='\t', textConnection(blastout)), blastf6) 
```

