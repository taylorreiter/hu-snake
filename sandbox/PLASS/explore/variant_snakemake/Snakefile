ENV = "env.yml"
NBHD = "hu-genome36"
TRIM = ["hard"]
PFAM_BASE=["PF00521_gyra"]

rule all:
    input: 
        #"outputs/paladin/{nbhd}.hardtrim.sam.flagstat"
        #expand("outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100-dom.out", nbhd = NBHD, trim = TRIM, pfam_base = PFAM_BASE),
        #expand("outputs/paladin/{nbhd}.{trim}trim.sort.bam.bai", nbhd = NBHD, trim = TRIM, pfam_base = PFAM_BASE)
        #expand("outputs/comp/{nbhd}_{trim}trim_{pfam_base}_k31.csv", nbhd = NBHD, trim = TRIM, pfam_base = PFAM_BASE) 
        dynamic("outputs/comp/cut{i}.txt")

# run per nbhd (definitely) 
# & per pfam domain? 

rule download_plass:
    output: "inputs/plass/{nbhd}.{trim}trim.plass.c100.fa" # shouldn't need to use clean if only dealing with one nbhd
    shell:'''
    touch {output} #place holder for downloading plass hardtrim results
    '''

rule format_plass_cut:
    output: "outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.fa"
    input: "inputs/plass/{nbhd}.{trim}trim.plass.c100.fa"
    shell:'''
    cut -d ' ' -f1 {input} > {output}
    '''

rule format_plass_dup:
    output: "outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.dup.fa"
    input: "outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.fa"
    shell:'''
    awk '(/^>/ && s[$0]++){{$0=$0"_"s[$0]}}1;' {input} > {output}
    '''

rule download_pfam:
    output: "inputs/pfam/{pfam_base}.sto"
    params: 
        out_dir = "inputs/pfam"
    shell:'''
    pfam=$(echo {wildcards.pfam_base} | cut -f1 -d"_")
    wget -O {output} https://pfam.xfam.org/family/${{pfam}}/alignment/full
    '''

rule hmmbuild:
    input: "inputs/pfam/{pfam_base}.sto"
    output: "outputs/hmmbuild/{pfam_base}.hmm"
    shell: '''
    hmmbuild outputs/hmmbuild/{wildcards.pfam_base}.hmm inputs/pfam/{wildcards.pfam_base}.sto   
    hmmpress outputs/hmmbuild/{wildcards.pfam_base}.hmm
'''

rule hmmscan:
    output:
        out = "outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100.out",
        tbl = "outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100-tbl.out",
        dom = "outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100-dom.out"
    input:
        hmm = "outputs/hmmbuild/{pfam_base}.hmm",
        faa = "outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.dup.fa"
    conda: ENV
    shell:'''
    hmmscan -T 100 -o {output.out} --tblout {output.tbl} --domtblout {output.dom} {input.hmm} {input.faa} 
'''

rule get_rhmmer:
    output: "rhmmer.R"
    shell:'''
    wget -O rhmmer.R https://raw.githubusercontent.com/arendsee/rhmmer/master/R/parse.R
    '''

rule def_overlap_window_and_find_reads:
# get the names of the PLASS assembled aa seqs that match the PFAM
# domain of interest.
    input:
        dom = "outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100-dom.out",
        rhmmer = "rhmmer.R"
    output:
        keep = "outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100-NAMES.txt"
    conda: ENV
    script:'variant-workflow-hmm-matches.R'

rule paladin_index:
    output: "outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.dup.fa.bwt"
    input: "outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.dup.fa"
    conda: ENV
    shell:'''
    paladin index -r3 {input}
    '''

rule paladin_align:
    output: "outputs/paladin/{nbhd}.{trim}trim.sam"
    input:
        indx="outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.dup.fa.bwt",
        reads="inputs/reads/{nbhd}.{trim}trim.reads.gz"
    params: 
        indx="outputs/plass/{nbhd}.{trim}trim.plass.c100.cut.dup.fa"
    conda: ENV
    shell:'''
    paladin align -f 125 -t 2 {params.indx} {input.reads} > {output}
    '''

rule samtools_flagstat_paladin:
    output: "outputs/paladin/{nbhd}.{trim}trim.sam.flagstat"
    input: "outputs/paladin/{nbhd}.{trim}trim.sam"
    conda: ENV
    shell:'''
    samtools flagstat {input} > {output}
    '''

rule samtools_view_paladin:
    output: "outputs/paladin/{nbhd}.{trim}trim.bam"
    input: "outputs/paladin/{nbhd}.{trim}trim.sam"
    conda: ENV
    shell:'''
    samtools view -b {input} > {output}
    '''

rule samtools_sort_paladin:
    output: "outputs/paladin/{nbhd}.{trim}trim.sort.bam"
    input: "outputs/paladin/{nbhd}.{trim}trim.bam"
    conda: ENV
    shell:'''
    samtools sort {input} > {output}
    '''

rule samtools_index_paladin:
    output: "outputs/paladin/{nbhd}.{trim}trim.sort.bam.bai"
    input: "outputs/paladin/{nbhd}.{trim}trim.sort.bam"
    conda: ENV
    shell:'''
    samtools index {input} 
    '''

rule extract_plass_readnames_from_bam:
# extract names of reads for each aa seq bam section that matched 
# PFAM domain of interest
    output: dynamic("outputs/bam_subsets/{plass_match}-NAMES.txt") 
    input:
        plass_names = expand("outputs/hmmscan/{nbhd}.{trim}trim.plass.{pfam_base}-hmmscanT100-NAMES.txt", nbhd = NBHD, trim = TRIM, pfam_base=PFAM_BASE), 
        bai = expand("outputs/paladin/{nbhd}.{trim}trim.sort.bam.bai", nbhd = NBHD, trim = TRIM), 
        bam = expand("outputs/paladin/{nbhd}.{trim}trim.sort.bam", nbhd = NBHD, trim = TRIM) 
    run:
        import pysam
        import re
        
        with open(str(input.plass_names)) as f:
            plass_hmmscan_matches = f.readlines()

        plass_hmmscan_matches = [x.strip() for x in plass_hmmscan_matches] 

        samfile = pysam.AlignmentFile(str(input.bam), 'rb')

        for match in plass_hmmscan_matches:
            reads = []
            for read in samfile.fetch(match):
                name = re.sub('.*:', '', read.qname)
                reads.append(name)
                with open(f"outputs/bam_subsets/{match}-NAMES.txt", 'w') as outfile:
                    for s in reads:
                        outfile.write("%s\n" % s)
        samfile.close()


rule grab_plass_reads:
    output: "outputs/bam_subsets/{plass_match}.fa" # loses fq info
    input: 
        names = "outputs/bam_subsets/{plass_match}-NAMES.txt",
        reads=expand("inputs/reads/{nbhd}.{trim}trim.reads.gz", nbhd = NBHD, trim = TRIM)
    conda: ENV
    shell:'''
    ./extract-hmmscan-matches.py {input.names} {input.reads}  > {output} 
    '''

rule calc_plass_read_sigs:
    output: "outputs/bam_subsets/{plass_match}.sig"
    input: "outputs/bam_subsets/{plass_match}.fa"
    conda: ENV
    shell:'''
    sourmash compute -k 31 --scaled 1 -o {output} {input}
    '''

rule compare_plass_read_sigs:
    output: "outputs/comp/{nbhd}_{trim}trim_{pfam_base}_k31.csv"
    input: dynamic("outputs/bam_subsets/{plass_match}.sig")
    conda: ENV
    shell:'''
    sourmash compare -k 31 --csv {output} {input}
    '''

rule cut_dendo:
    output: dynamic("outputs/comp/cut{i}.txt")
    input: comp = expand("outputs/comp/{nbhd}_{trim}trim_{pfam_base}_k31.csv", nbhd = NBHD, trim = TRIM, pfam_base = PFAM_BASE)
    conda: ENV
    script: 'variant-workflow-cut-dendo.R'
